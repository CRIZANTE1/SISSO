import pandas as pd
import numpy as np
from typing import List, Optional, Dict, Any
from managers.supabase_config import get_supabase_client
import streamlit as st

# Import scipy opcionalmente
try:
    from scipy import stats
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    print("‚ö†Ô∏è SciPy n√£o est√° dispon√≠vel. Algumas funcionalidades estat√≠sticas podem estar limitadas.")

def fetch_kpi_data(user_email: Optional[str] = None,
                   start_date: Optional[str] = None, 
                   end_date: Optional[str] = None) -> pd.DataFrame:
    """Busca dados de KPI do Supabase"""
    try:
        supabase = get_supabase_client()
        query = supabase.table("kpi_monthly").select("*")
        
        if user_email:
            query = query.eq("created_by", user_email)
        if start_date:
            query = query.gte("period", start_date)
        if end_date:
            query = query.lte("period", end_date)
            
        data = query.order("period").execute().data
        return pd.DataFrame(data)
    except Exception as e:
        st.error(f"Erro ao buscar dados de KPI: {str(e)}")
        return pd.DataFrame()

def calculate_frequency_rate(accidents: int, hours_worked: float) -> float:
    """
    Calcula Taxa de Frequ√™ncia (TF) conforme NBR 14280
    
    F√≥rmula: (N¬∞ de acidentes x 1.000.000) / hora-homem trabalhada
    
    A TF indica a quantidade de acidentes ocorridos numa empresa em fun√ß√£o 
    da exposi√ß√£o ao risco (horas-homem de exposi√ß√£o ao risco).
    
    Par√¢metros de refer√™ncia:
    - TF at√© 20 = muito bom
    - 20,1-40 = bom  
    - 40,1-60 = ruim
    - acima de 60 = p√©ssima
    """
    if hours_worked is None or hours_worked == 0:
        return 0.0
    return (accidents / hours_worked) * 1_000_000

def calculate_severity_rate(lost_days: int, hours_worked: float, debited_days: int = 0) -> float:
    """
    Calcula Taxa de Gravidade (TG) conforme NBR 14280
    
    F√≥rmula: ((dias perdidos + dias debitados) x 1.000.000) / hora-homem trabalhada
    
    A TG mede o impacto ou severidade dos acidentes em termos de tempo de trabalho 
    perdido (ou que ser√° perdido) por cada milh√£o de horas-homem de exposi√ß√£o ao risco.
    
    Args:
        lost_days: Dias que o trabalhador ficou afastado por conta do acidente
        hours_worked: Total de horas-homem trabalhadas
        debited_days: Dias debitados para casos graves (incapacidade permanente, morte)
                      Ex: morte = 6000 dias, amputa√ß√£o de m√£o = 3000 dias
    """
    if hours_worked is None or hours_worked == 0:
        return 0.0
    return ((lost_days + debited_days) / hours_worked) * 1_000_000

def get_frequency_rate_interpretation(tf_value: float) -> dict:
    """
    Retorna interpreta√ß√£o da Taxa de Frequ√™ncia conforme par√¢metros de refer√™ncia
    """
    if tf_value <= 20:
        return {
            "classification": "Muito Bom",
            "color": "success",
            "icon": "‚úÖ",
            "description": "Excelente desempenho em preven√ß√£o de acidentes"
        }
    elif tf_value <= 40:
        return {
            "classification": "Bom", 
            "color": "info",
            "icon": "üìä",
            "description": "Bom desempenho, manter pr√°ticas atuais"
        }
    elif tf_value <= 60:
        return {
            "classification": "Ruim",
            "color": "warning", 
            "icon": "‚ö†Ô∏è",
            "description": "Desempenho ruim, revisar procedimentos de seguran√ßa"
        }
    else:
        return {
            "classification": "P√©ssimo",
            "color": "danger",
            "icon": "üö®", 
            "description": "Desempenho cr√≠tico, a√ß√£o imediata necess√°ria"
        }

def get_severity_rate_interpretation(tg_value: float) -> dict:
    """
    Retorna interpreta√ß√£o da Taxa de Gravidade
    """
    if tg_value <= 50:
        return {
            "classification": "Excelente",
            "color": "success",
            "icon": "‚úÖ",
            "description": "Baixo impacto dos acidentes"
        }
    elif tg_value <= 100:
        return {
            "classification": "Aceit√°vel",
            "color": "info", 
            "icon": "üìä",
            "description": "Impacto moderado, monitorar"
        }
    elif tg_value <= 200:
        return {
            "classification": "Elevado",
            "color": "warning",
            "icon": "‚ö†Ô∏è",
            "description": "Alto impacto, revisar medidas preventivas"
        }
    else:
        return {
            "classification": "Cr√≠tico",
            "color": "danger",
            "icon": "üö®",
            "description": "Impacto cr√≠tico, investiga√ß√£o imediata necess√°ria"
        }

def calculate_poisson_control_limits(df: pd.DataFrame, 
                                   accidents_col: str = 'accidents_total',
                                   hours_col: str = 'hours') -> pd.DataFrame:
    """Calcula limites de controle Poisson para eventos raros"""
    df = df.copy()
    
    # Taxa m√©dia de acidentes por hora
    total_accidents = df[accidents_col].sum()
    total_hours = df[hours_col].sum()
    mean_rate = total_accidents / total_hours if total_hours > 0 else 0
    
    # Valor esperado para cada per√≠odo
    df['expected'] = df[hours_col] * mean_rate
    
    # Limites de controle (3-sigma)
    df['ucl'] = df['expected'] + 3 * np.sqrt(df['expected'])
    df['lcl'] = np.maximum(0, df['expected'] - 3 * np.sqrt(df['expected']))
    
    # Identificar pontos fora de controle
    df['out_of_control'] = (df[accidents_col] > df['ucl']) | (df[accidents_col] < df['lcl'])
    
    return df

def calculate_ewma(df: pd.DataFrame, 
                  value_col: str, 
                  lambda_param: float = 0.2) -> pd.DataFrame:
    """Calcula EWMA (Exponentially Weighted Moving Average)"""
    df = df.copy()
    df = df.sort_values('period')
    
    # Inicializa com a m√©dia dos primeiros valores
    initial_mean = df[value_col].head(12).mean() if len(df) >= 12 else df[value_col].mean()
    
    ewma_values = []
    ewma = initial_mean
    
    for value in df[value_col]:
        ewma = lambda_param * value + (1 - lambda_param) * ewma
        ewma_values.append(ewma)
    
    df['ewma'] = ewma_values
    
    # Limites de controle para EWMA
    variance = df[value_col].var()
    sigma_ewma = np.sqrt((lambda_param / (2 - lambda_param)) * variance)
    
    df['ewma_ucl'] = initial_mean + 3 * sigma_ewma
    df['ewma_lcl'] = initial_mean - 3 * sigma_ewma
    
    return df

def detect_control_chart_patterns(df: pd.DataFrame, 
                                value_col: str, 
                                ucl_col: str, 
                                lcl_col: str) -> Dict[str, List[int]]:
    """Detecta padr√µes de controle estat√≠stico"""
    patterns = {
        'out_of_control': [],
        'trend_up': [],
        'trend_down': [],
        'runs_above_center': [],
        'runs_below_center': []
    }
    
    values = df[value_col].values
    ucl_values = df[ucl_col].values
    lcl_values = df[lcl_col].values
    center_line = values.mean()
    
    for i in range(len(values)):
        # Pontos fora de controle
        if values[i] > ucl_values[i] or values[i] < lcl_values[i]:
            patterns['out_of_control'].append(i)
        
        # Tend√™ncia ascendente (8 pontos consecutivos)
        if i >= 7:
            if all(values[j] > values[j-1] for j in range(i-7, i+1)):
                patterns['trend_up'].append(i)
        
        # Tend√™ncia descendente (8 pontos consecutivos)
        if i >= 7:
            if all(values[j] < values[j-1] for j in range(i-7, i+1)):
                patterns['trend_down'].append(i)
    
    return patterns

def generate_kpi_summary(df: pd.DataFrame) -> Dict[str, Any]:
    """Gera resumo dos KPIs com interpreta√ß√µes conforme NBR 14280"""
    if df.empty:
        return {}
    
    # Calcula totais acumulados para todo o per√≠odo
    total_accidents = df['accidents_total'].sum()
    total_lost_days = df['lost_days_total'].sum()
    total_hours = df['hours'].sum()
    total_fatalities = df.get('fatalities', pd.Series([0] * len(df))).sum()
    total_debited_days = df.get('debited_days', pd.Series([0] * len(df))).sum()
    
    # C√°lculos acumulados para todo o per√≠odo
    freq_rate = calculate_frequency_rate(total_accidents, total_hours)
    sev_rate = calculate_severity_rate(total_lost_days, total_hours, total_debited_days)
    
    # Interpreta√ß√µes conforme par√¢metros de refer√™ncia
    freq_interpretation = get_frequency_rate_interpretation(freq_rate)
    sev_interpretation = get_severity_rate_interpretation(sev_rate)
    
    # Compara√ß√£o com per√≠odo anterior (√∫ltimo per√≠odo vs pen√∫ltimo)
    latest_period = df['period'].max()
    latest_data = df[df['period'] == latest_period].iloc[0]
    
    prev_period_data = df[df['period'] < latest_period]
    if not prev_period_data.empty:
        prev_data = prev_period_data.iloc[-1]
        prev_freq_rate = calculate_frequency_rate(
            prev_data['accidents_total'], 
            prev_data['hours']
        )
        prev_sev_rate = calculate_severity_rate(
            prev_data['lost_days_total'], 
            prev_data['hours'],
            prev_data.get('debited_days', 0)
        )
        
        # Evita varia√ß√µes artificiais quando o per√≠odo anterior √© zero ou inexistente
        freq_change = ((freq_rate - prev_freq_rate) / prev_freq_rate * 100) if prev_freq_rate and prev_freq_rate > 0 else None
        sev_change = ((sev_rate - prev_sev_rate) / prev_sev_rate * 100) if prev_sev_rate and prev_sev_rate > 0 else None
    else:
        freq_change = None
        sev_change = None
    
    return {
        'latest_period': latest_period,
        'frequency_rate': freq_rate,
        'severity_rate': sev_rate,
        'frequency_change': freq_change,
        'severity_change': sev_change,
        'total_accidents': total_accidents,
        'total_fatalities': total_fatalities,
        'total_lost_days': total_lost_days,
        'total_debited_days': total_debited_days,
        'total_hours': total_hours,
        'frequency_interpretation': freq_interpretation,
        'severity_interpretation': sev_interpretation
    }

def calculate_forecast(df: pd.DataFrame, months_ahead: int = 1) -> Dict[str, Any]:
    """Calcula previs√µes para os pr√≥ximos meses baseadas em tend√™ncias hist√≥ricas"""
    if df.empty or len(df) < 3:
        return {}
    
    try:
        # Ordena por per√≠odo
        df_sorted = df.sort_values('period').copy()
        
        # Calcula m√©dias m√≥veis dos √∫ltimos 3 meses
        recent_data = df_sorted.tail(3)
        
        # Previs√µes baseadas em m√©dias m√≥veis simples
        forecasts = {}
        
        # Taxa de Frequ√™ncia - usa m√©dia m√≥vel dos √∫ltimos 3 meses
        if 'hours' in df_sorted.columns and 'accidents_total' in df_sorted.columns:
            df_sorted['freq_rate'] = (df_sorted['accidents_total'] / df_sorted['hours']) * 1_000_000
            
            # Calcula tend√™ncia simples comparando √∫ltimos 3 meses
            recent_freq = df_sorted['freq_rate'].tail(3).values
            if len(recent_freq) >= 2:
                # Tend√™ncia baseada na diferen√ßa entre √∫ltimo e pen√∫ltimo
                trend = recent_freq[-1] - recent_freq[-2] if len(recent_freq) >= 2 else 0
                
                # Previs√£o: √∫ltimo valor + tend√™ncia
                predicted_freq = recent_freq[-1] + trend
                predicted_freq = max(0, predicted_freq)  # N√£o pode ser negativo
                
                forecasts['frequency_rate'] = {
                    'predicted': predicted_freq,
                    'trend': 'increasing' if trend > 0 else 'decreasing' if trend < 0 else 'stable',
                    'confidence': 0.7  # Confian√ßa fixa para simplicidade
                }
        
        # Taxa de Gravidade - usa m√©dia m√≥vel dos √∫ltimos 3 meses
        if 'hours' in df_sorted.columns and 'lost_days_total' in df_sorted.columns:
            df_sorted['sev_rate'] = (df_sorted['lost_days_total'] / df_sorted['hours']) * 1_000_000
            
            recent_sev = df_sorted['sev_rate'].tail(3).values
            if len(recent_sev) >= 2:
                trend = recent_sev[-1] - recent_sev[-2] if len(recent_sev) >= 2 else 0
                
                predicted_sev = recent_sev[-1] + trend
                predicted_sev = max(0, predicted_sev)  # N√£o pode ser negativo
                
                forecasts['severity_rate'] = {
                    'predicted': predicted_sev,
                    'trend': 'increasing' if trend > 0 else 'decreasing' if trend < 0 else 'stable',
                    'confidence': 0.7
                }
        
        # Total de Acidentes - usa m√©dia m√≥vel dos √∫ltimos 3 meses
        if 'accidents_total' in df_sorted.columns:
            recent_acc = df_sorted['accidents_total'].tail(3).values
            if len(recent_acc) >= 2:
                trend = recent_acc[-1] - recent_acc[-2] if len(recent_acc) >= 2 else 0
                
                predicted_acc = recent_acc[-1] + trend
                predicted_acc = max(0, round(predicted_acc))  # Arredonda e n√£o pode ser negativo
                
                forecasts['total_accidents'] = {
                    'predicted': predicted_acc,
                    'trend': 'increasing' if trend > 0 else 'decreasing' if trend < 0 else 'stable',
                    'confidence': 0.7
                }
        
        # Dias Perdidos - usa m√©dia m√≥vel dos √∫ltimos 3 meses
        if 'lost_days_total' in df_sorted.columns:
            recent_days = df_sorted['lost_days_total'].tail(3).values
            if len(recent_days) >= 2:
                trend = recent_days[-1] - recent_days[-2] if len(recent_days) >= 2 else 0
                
                predicted_days = recent_days[-1] + trend
                predicted_days = max(0, round(predicted_days))  # Arredonda e n√£o pode ser negativo
                
                forecasts['lost_days'] = {
                    'predicted': predicted_days,
                    'trend': 'increasing' if trend > 0 else 'decreasing' if trend < 0 else 'stable',
                    'confidence': 0.7
                }
        
        # Horas trabalhadas (assume valor m√©dio dos √∫ltimos 3 meses)
        if 'hours' in df_sorted.columns:
            avg_hours = float(recent_data['hours'].mean())
            forecasts['hours'] = {
                'predicted': round(avg_hours),
                'trend': 'stable',
                'confidence': 0.8
            }
        
        return forecasts
        
    except Exception as e:
        # Em caso de erro, retorna dicion√°rio vazio
        return {}

def generate_forecast_recommendations(forecasts: Dict[str, Any]) -> List[str]:
    """Gera recomenda√ß√µes baseadas nas previs√µes"""
    recommendations = []
    
    # An√°lise da taxa de frequ√™ncia
    if 'frequency_rate' in forecasts:
        freq_data = forecasts['frequency_rate']
        if freq_data['trend'] == 'increasing' and freq_data['predicted'] > 5:
            recommendations.append("üö® **CR√çTICO:** Taxa de frequ√™ncia prevista em alta - implementar medidas preventivas urgentes")
        elif freq_data['trend'] == 'increasing':
            recommendations.append("‚ö†Ô∏è **ATEN√á√ÉO:** Taxa de frequ√™ncia em tend√™ncia de alta - revisar procedimentos")
        elif freq_data['trend'] == 'decreasing':
            recommendations.append("‚úÖ **POSITIVO:** Taxa de frequ√™ncia em tend√™ncia de melhoria - manter pr√°ticas atuais")
    
    # An√°lise da taxa de gravidade
    if 'severity_rate' in forecasts:
        sev_data = forecasts['severity_rate']
        if sev_data['trend'] == 'increasing' and sev_data['predicted'] > 50:
            recommendations.append("üö® **CR√çTICO:** Taxa de gravidade prevista em alta - investigar causas raiz")
        elif sev_data['trend'] == 'increasing':
            recommendations.append("‚ö†Ô∏è **ATEN√á√ÉO:** Taxa de gravidade em tend√™ncia de alta - implementar medidas preventivas")
        elif sev_data['trend'] == 'decreasing':
            recommendations.append("‚úÖ **POSITIVO:** Taxa de gravidade em tend√™ncia de melhoria - documentar boas pr√°ticas")
    
    # An√°lise do total de acidentes
    if 'total_accidents' in forecasts:
        acc_data = forecasts['total_accidents']
        if acc_data['predicted'] > 2:
            recommendations.append("‚ö†Ô∏è **MONITORAR:** Previs√£o de acidentes elevada - intensificar treinamentos")
        elif acc_data['predicted'] == 0:
            recommendations.append("üéØ **META:** Previs√£o de zero acidentes - manter excelente desempenho")
    
    return recommendations

def fetch_detailed_accidents(user_email: str, start_date=None, end_date=None) -> pd.DataFrame:
    """
    Busca dados detalhados de acidentes do usu√°rio atual
    """
    try:
        from managers.supabase_config import get_service_role_client
        supabase = get_service_role_client()
        
        # Busca dados do usu√°rio
        user_response = supabase.table("profiles").select("id, sites").eq("email", user_email).execute()
        
        if not user_response.data:
            return pd.DataFrame()
        
        user_data = user_response.data[0]
        user_sites = user_data.get("sites", [])
        
        if not user_sites:
            return pd.DataFrame()
        
        # Busca dados de acidentes
        query = supabase.table("accidents").select("*").in_("site_id", user_sites)
        
        if start_date:
            query = query.gte("occurred_at", start_date.isoformat())
        if end_date:
            query = query.lte("occurred_at", end_date.isoformat())
            
        response = query.order("occurred_at", desc=True).execute()
        
        if response and hasattr(response, 'data') and response.data:
            return pd.DataFrame(response.data)
        return pd.DataFrame()
        
    except Exception as e:
        st.error(f"Erro ao buscar dados de acidentes: {str(e)}")
        return pd.DataFrame()

def analyze_accidents_by_category(accidents_df: pd.DataFrame) -> Dict[str, Any]:
    """
    Analisa acidentes por categoria (les√£o/fatalidade) e calcula frequ√™ncia
    """
    if accidents_df.empty:
        return {}
    
    # Converte data para datetime se necess√°rio
    if 'occurred_at' in accidents_df.columns:
        accidents_df['occurred_at'] = pd.to_datetime(accidents_df['occurred_at'])
        accidents_df['year_month'] = accidents_df['occurred_at'].dt.to_period('M')
    
    # An√°lise por tipo de acidente
    type_analysis = accidents_df.groupby('type').agg({
        'id': 'count',
        'lost_days': 'sum',
        'is_fatal': 'sum'
    }).rename(columns={'id': 'count'})
    
    # An√°lise por classifica√ß√£o
    classification_analysis = accidents_df.groupby('classification').agg({
        'id': 'count',
        'lost_days': 'sum'
    }).rename(columns={'id': 'count'})
    
    # An√°lise por parte do corpo
    body_part_analysis = accidents_df.groupby('body_part').agg({
        'id': 'count',
        'lost_days': 'sum'
    }).rename(columns={'id': 'count'})
    
    # An√°lise por causa raiz
    root_cause_analysis = accidents_df.groupby('root_cause').agg({
        'id': 'count',
        'lost_days': 'sum'
    }).rename(columns={'id': 'count'})
    
    # An√°lise temporal (√∫ltimos 12 meses)
    if 'year_month' in accidents_df.columns:
        temporal_analysis = accidents_df.groupby('year_month').agg({
            'id': 'count',
            'lost_days': 'sum',
            'is_fatal': 'sum'
        }).rename(columns={'id': 'count'})
    else:
        temporal_analysis = pd.DataFrame()
    
    # Converte para formato mais leg√≠vel
    def format_analysis(df, name):
        if df.empty:
            return {}
        
        result = {}
        for idx, row in df.iterrows():
            if pd.isna(idx) or idx == '':
                continue
            result[str(idx)] = {
                'count': int(row['count']),
                'lost_days': int(row.get('lost_days', 0)),
                'fatalities': int(row.get('is_fatal', 0)) if 'is_fatal' in row else 0
            }
        return result
    
    return {
        'by_type': format_analysis(type_analysis, 'Tipo'),
        'by_classification': format_analysis(classification_analysis, 'Classifica√ß√£o'),
        'by_body_part': format_analysis(body_part_analysis, 'Parte do Corpo'),
        'by_root_cause': format_analysis(root_cause_analysis, 'Causa Raiz'),
        'temporal': format_analysis(temporal_analysis, 'Temporal'),
        'total_accidents': len(accidents_df),
        'total_fatalities': int(accidents_df['is_fatal'].sum()) if 'is_fatal' in accidents_df.columns else 0,
        'total_lost_days': int(accidents_df['lost_days'].sum()) if 'lost_days' in accidents_df.columns else 0,
        'frequency_by_period': calculate_accident_frequency_by_period(accidents_df)
    }

def calculate_accident_frequency_by_period(accidents_df: pd.DataFrame) -> Dict[str, Any]:
    """
    Calcula a frequ√™ncia de acidentes por per√≠odo (mensal)
    """
    if accidents_df.empty or 'occurred_at' not in accidents_df.columns:
        return {}
    
    # Converte data para datetime
    accidents_df['occurred_at'] = pd.to_datetime(accidents_df['occurred_at'])
    accidents_df['year_month'] = accidents_df['occurred_at'].dt.to_period('M')
    
    # Agrupa por per√≠odo e tipo
    period_analysis = accidents_df.groupby(['year_month', 'type']).size().unstack(fill_value=0)
    
    # Calcula frequ√™ncia relativa
    period_totals = period_analysis.sum(axis=1)
    period_frequency = {}
    
    for period in period_analysis.index:
        period_str = str(period)
        period_frequency[period_str] = {
            'total': int(period_totals[period]),
            'fatal': int(period_analysis.loc[period, 'fatal']) if 'fatal' in period_analysis.columns else 0,
            'lesao': int(period_analysis.loc[period, 'lesao']) if 'lesao' in period_analysis.columns else 0,
            'sem_lesao': int(period_analysis.loc[period, 'sem_lesao']) if 'sem_lesao' in period_analysis.columns else 0
        }
    
    return period_frequency